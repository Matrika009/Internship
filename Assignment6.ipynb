{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d77b48f",
   "metadata": {},
   "source": [
    "Q1: Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9f2921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    1.                            \"Baby Shark Dance\"[6]   \n",
      "1    2.                                   \"Despacito\"[9]   \n",
      "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
      "3    4.                                  \"Bath Song\"[18]   \n",
      "4    5.                               \"Shape of You\"[19]   \n",
      "5    6.                              \"See You Again\"[22]   \n",
      "6    7.                          \"Wheels on the Bus\"[27]   \n",
      "7    8.                \"Phonics Song with Two Words\"[28]   \n",
      "8    9.                                \"Uptown Funk\"[29]   \n",
      "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
      "10  11.                              \"Gangnam Style\"[31]   \n",
      "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
      "12  13.                             \"Dame Tu Cosita\"[37]   \n",
      "13  14.                                     \"Axel F\"[38]   \n",
      "14  15.                                      \"Sugar\"[39]   \n",
      "15  16.                             \"Counting Stars\"[40]   \n",
      "16  17.                                       \"Roar\"[41]   \n",
      "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
      "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
      "19  20.                             \"Lakdi Ki Kathi\"[44]   \n",
      "20  21.                                      \"Sorry\"[45]   \n",
      "21  22.                          \"Thinking Out Loud\"[46]   \n",
      "22  23.          \"Humpty the train on a fruits ride\"[47]   \n",
      "23  24.                                 \"Dark Horse\"[48]   \n",
      "24  25.                                    \"Perfect\"[49]   \n",
      "25  26.                                 \"Let Her Go\"[50]   \n",
      "26  27.                                      \"Faded\"[51]   \n",
      "27  28.                      \"Shree Hanuman Chalisa\"[52]   \n",
      "28  29.                             \"Girls Like You\"[53]   \n",
      "29  30.                                    \"Lean On\"[54]   \n",
      "\n",
      "                                               Artist Upload Date  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories       13.65   \n",
      "1                                          Luis Fonsi        8.32   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs        6.84   \n",
      "3                          Cocomelon - Nursery Rhymes        6.50   \n",
      "4                                          Ed Sheeran        6.14   \n",
      "5                                         Wiz Khalifa        6.09   \n",
      "6                          Cocomelon - Nursery Rhymes        5.71   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs        5.57   \n",
      "8                                         Mark Ronson        5.09   \n",
      "9                                         Miroshka TV        5.01   \n",
      "10                                        officialpsy        4.96   \n",
      "11                                         Get Movies        4.57   \n",
      "12                                      Ultra Records        4.48   \n",
      "13                                         Crazy Frog        4.16   \n",
      "14                                           Maroon 5        3.97   \n",
      "15                                        OneRepublic        3.92   \n",
      "16                                         Katy Perry        3.91   \n",
      "17                         Cocomelon - Nursery Rhymes        3.84   \n",
      "18                                            Shakira        3.78   \n",
      "19                                       Jingle Toons        3.76   \n",
      "20                                      Justin Bieber        3.74   \n",
      "21                                         Ed Sheeran        3.69   \n",
      "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs        3.63   \n",
      "23                                         Katy Perry        3.63   \n",
      "24                                         Ed Sheeran        3.60   \n",
      "25                                          Passenger        3.56   \n",
      "26                                        Alan Walker        3.55   \n",
      "27                              T-Series Bhakti Sagar        3.54   \n",
      "28                                           Maroon 5        3.52   \n",
      "29                               Major Lazer Official        3.50   \n",
      "\n",
      "                Views  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4    January 30, 2017  \n",
      "5       April 6, 2015  \n",
      "6        May 24, 2018  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9   February 27, 2018  \n",
      "10      July 15, 2012  \n",
      "11   January 31, 2012  \n",
      "12      April 5, 2018  \n",
      "13      June 16, 2009  \n",
      "14   January 14, 2015  \n",
      "15       May 31, 2013  \n",
      "16  September 5, 2013  \n",
      "17      June 25, 2018  \n",
      "18       June 4, 2010  \n",
      "19      June 14, 2018  \n",
      "20   October 22, 2015  \n",
      "21    October 7, 2014  \n",
      "22   January 26, 2018  \n",
      "23  February 20, 2014  \n",
      "24   November 9, 2017  \n",
      "25      July 25, 2012  \n",
      "26   December 3, 2015  \n",
      "27       May 10, 2011  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "time.sleep(2)\n",
    "data=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]\n",
    "tab=driver.find_elements(By.XPATH, '//table[contains(@class, \"wikitable sortable jquery-tablesorter\")]//tbody//tr//td')\n",
    "for i in tab:\n",
    "    tab1=i.text\n",
    "    data.append(tab1)\n",
    "    \n",
    "for x in range(0,len(data),6):\n",
    "    Rank.append(data[x])\n",
    "for x in range(1,len(data),6):\n",
    "    Name.append(data[x])\n",
    "for x in range(2,len(data),6):\n",
    "    Artist.append(data[x])\n",
    "for x in range(3,len(data),6):\n",
    "    Upload_Date.append(data[x])\n",
    "for x in range(4,len(data),6):\n",
    "    Views.append(data[x])\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"Rank\":Rank[:30],\"Name\": Name[:30],\"Artist\": Artist[:30],\"Upload Date\":Upload_Date[:30],\"Views\":Views[:30]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b09b26",
   "metadata": {},
   "source": [
    "Q2: Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dbf2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'AUSTRALIA WOMEN TOUR OF INDIA 2023-24']\n",
      "['AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'ENGLAND WOMEN TOUR OF INDIA 2023-24', 'AUSTRALIA WOMEN TOUR OF INDIA 2023-24'] ['1 DECEMBER, 2023', '3 DECEMBER, 2023', '6 DECEMBER, 2023', '9 DECEMBER, 2023', '10 DECEMBER, 2023', '14 DECEMBER, 2023', '21 DECEMBER, 2023'] ['7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:30 AM IST', '9:30 AM IST'] ['Shaheed Veer Narayan Singh International Cricket Stadium, Raipur', 'M Chinnaswamy Stadium, Bengaluru', 'Wankhede Stadium, Mumbai', 'Wankhede Stadium, Mumbai', 'Wankhede Stadium, Mumbai', 'DY Patil Stadium, NAVI MUMBAI', 'Wankhede Stadium, Mumbai']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(2)\n",
    "search_n=driver.find_element(By.XPATH,\"/html/body/header/div[3]/div[1]/ul/div[1]/a[2]\")\n",
    "search_n.click()\n",
    "time.sleep(3)\n",
    "\n",
    "Series=[]\n",
    "Place=[]\n",
    "DateTime=[]\n",
    "Date=[]\n",
    "Time_Note=[]\n",
    "Date1=[]\n",
    "Time=[]\n",
    "\n",
    "Series_t=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "try:\n",
    "    for i in Series_t:\n",
    "        Series1=i.text\n",
    "        Series.append(Series1)\n",
    "\n",
    "except NoSuchElementException:\n",
    "    Series.append(\"-\")\n",
    "    \n",
    "Date_t=driver.find_elements(By.XPATH,'//div[@class=\"match-date-info\"]//div')\n",
    "try:\n",
    "    for i in Date_t:\n",
    "        Date1=i.text\n",
    "        DateTime.append(Date1)\n",
    "except NoSuchElementException:\n",
    "    DateTime.append(\"-\")\n",
    "for x in range(0,len(DateTime),2):\n",
    "    Date.append(DateTime[x])\n",
    "for x in range(1,len(DateTime),2):\n",
    "    Time.append(DateTime[x])\n",
    "\n",
    "Place_t=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "try:\n",
    "    for i in Place_t:\n",
    "        Place1=i.text\n",
    "        Place.append(Place1)\n",
    "\n",
    "except NoSuchElementException:\n",
    "    Place.append(\"-\")\n",
    "\n",
    "print(Series,Date,Time,Place)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81affd05",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c47dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33'] ['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Gujarat', 'Karnataka', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands'] ['2,632,792', '1,630,208', '1,584,764', '1,502,899', '1,493,127', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '487,805', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '34,433', '33,481', '28,723', '27,870', '27,283', '24,603', '22,287', '-'] ['2,632,792', '1,630,208', '1,584,764', '1,502,899', '1,493,127', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '487,805', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '34,433', '33,481', '28,723', '27,870', '27,283', '24,603', '22,287', '-'] ['13.94%', '8.63%', '8.39%', '7.96%', '7.91%', '5.77%', '4.99%', '4.57%', '4.56%', '4.29%', '4.14%', '4.10%', '3.89%', '2.81%', '2.79%', '2.58%', '1.67%', '1.61%', '1.57%', '1.30%', '0.83%', '0.81%', '0.39%', '0.26%', '0.22%', '0.18%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.12%', '-'] ['399.921', '247.629', '240.726', '228.290', '226.806', '165.556', '143.179', '131.083', '130.791', '122.977', '118.733', '117.703', '111.519', '80.562', '79.957', '74.098', '47.982', '46.187', '45.145', '37.351', '23.690', '23.369', '11.115', '7.571', '6.397', '5.230', '5.086', '4.363', '4.233', '4.144', '3.737', '3.385', '-']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.statisticstimes.com/economy/india/indian-states-gdp.php\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "data = []\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP18_19cp=[]\n",
    "GSDP19_20cp=[]\n",
    "Share=[]\n",
    "GDP_bill=[]\n",
    "\n",
    "for x in range(1,34):\n",
    "    al=[]\n",
    "    for y in range(1,9):\n",
    "        designation=driver.find_elements(By.XPATH,f\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{x}]/td[{y}]\")\n",
    "        for i in designation:\n",
    "            tab1=i.text\n",
    "            al.append(tab1)\n",
    "\n",
    "    Rank.append(al[0])\n",
    "    State.append(al[1])\n",
    "    GSDP19_20cp.append(al[2])\n",
    "    GSDP18_19cp.append(al[3])\n",
    "    Share.append(al[4])\n",
    "    GDP_bill.append(al[5])\n",
    "    \n",
    "    \n",
    "\n",
    "print(Rank, State, GSDP18_19cp,GSDP18_19cp,Share,GDP_bill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe464468",
   "metadata": {},
   "source": [
    "Q4: Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f77f7880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LouisShark / chatgpt_system_prompt', 'run-llama / rags', 'linexjlin / GPTs', '1Panel-dev / 1Panel', 'GrowingGit / GitHub-Chinese-Top-Charts', 'atomicals / atomicals-js', 'opa334 / TrollStore', 'jordan-cutler / path-to-senior-engineer-handbook', 'BurntSushi / ripgrep', 'bgstaal / multipleWindow3dScene', 'Ftindy / IPTV-URL', 'yairm210 / Unciv', 'pointfreeco / swift-composable-architecture', 'microsoft / AI-For-Beginners', 'spring-projects / spring-boot', 'biomejs / biome', 'udlbook / udlbook', 'nlohmann / json', 'Ma-Lab-Berkeley / CRATE', 'ShinoKana / multipleWindow3dScene', 'goniszewski / grimoire', 'zennomi / Seg-Mirror', 'googleapis / google-api-php-client', 'grpc-ecosystem / grpc-gateway', 'kamranahmedse / developer-roadmap'] ['LouisShark / chatgpt_system_prompt', 'run-llama / rags', 'linexjlin / GPTs', '1Panel-dev / 1Panel', 'GrowingGit / GitHub-Chinese-Top-Charts', 'atomicals / atomicals-js', 'opa334 / TrollStore', 'jordan-cutler / path-to-senior-engineer-handbook', 'BurntSushi / ripgrep', 'bgstaal / multipleWindow3dScene', 'Ftindy / IPTV-URL', 'yairm210 / Unciv', 'pointfreeco / swift-composable-architecture', 'microsoft / AI-For-Beginners', 'spring-projects / spring-boot', 'biomejs / biome', 'udlbook / udlbook', 'nlohmann / json', 'Ma-Lab-Berkeley / CRATE', 'ShinoKana / multipleWindow3dScene', 'goniszewski / grimoire', 'zennomi / Seg-Mirror', 'googleapis / google-api-php-client', 'grpc-ecosystem / grpc-gateway', 'kamranahmedse / developer-roadmap'] ['C', 'Python', '-', 'Go', 'Java', 'TypeScript', 'C', '-', 'Rust', 'JavaScript', '-', 'Kotlin', 'Swift', 'Jupyter Notebook', 'Java', 'Rust', 'Jupyter Notebook', 'C++', 'Python', 'JavaScript', 'Svelte', 'JavaScript', 'PHP', 'Go', 'TypeScript'] ['364', '382', '848', '1,317', '10,053', '136', '666', '253', '1,817', '1,699', '58', '1,346', '1,084', '3,737', '39,875', '136', '640', '6,362', '66', '35', '12', '63', '3,624', '2,071', '35,607']\n",
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "tab1=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "tab1.click()\n",
    "time.sleep(3)\n",
    "\n",
    "tab2=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "tab2.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"Box\")]')\n",
    "title_Child=titles.find_elements(By.XPATH, '//h2[contains(@class, \"h3 lh-condensed\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Reptitle.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Reptitle.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//p[contains(@class, \"col-9 color-fg-muted my-1 pr-4\")]')\n",
    "\n",
    "        \n",
    "for x in range(1,len(Reptitle)+1):\n",
    "    try:\n",
    "        titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]//div//span//span[2]')\n",
    "        Languageused.append(titles.text)\n",
    "    except NoSuchElementException:\n",
    "        Languageused.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]//h2')\n",
    "        RepDesc.append(titles.text)\n",
    "    except NoSuchElementException:\n",
    "        RepDesc.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]//div[2]/a[2]')\n",
    "        ContriCount.append(titles.text)\n",
    "    except NoSuchElementException:\n",
    "        ContriCount.append(\"-\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "print(Reptitle,RepDesc,Languageused,ContriCount)\n",
    "print(len(Reptitle),len(RepDesc),len(Languageused),len(ContriCount))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53933353",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_Child=titles.find_elements(By.XPATH, '//div[contains(@class, \"f6 color-fg-muted mt-2\")]//a[2]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        ContriCount.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        ContriCount.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//span[contains(@class, \"d-inline-block ml-0 mr-3\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Languageused.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Languageused.append(\"-\")\n",
    "        \n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        RepDesc.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        RepDesc.append(\"-\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in range(1,10):\n",
    "#    titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]')\n",
    "#    print(titles.text)\n",
    "\n",
    "    try:\n",
    "        titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]//div//span//span[2]')\n",
    "#    ch_class=titles.find_element(By.XPATH, '//span[contains(@class, \"repo-language-color\")]')\n",
    "#        if titles:\n",
    "#        ch_class1=titles.find_element(By.XPATH, '//span[contains(@class, \"d-inline-block ml-0 mr-3\")]')\n",
    "        print(titles.text)\n",
    "    except NoSuchElementException:\n",
    "        print(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d765933",
   "metadata": {},
   "source": [
    "Q5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12f84e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Taylor Swift', 'Drake', 'Dolly Parton', 'Morgan Wallen', 'ENHYPEN', 'Zach Bryan', 'Olivia Rodrigo', 'Stray Kids', 'Chris Stapleton', 'Luke Combs', 'SZA', 'Jung Kook', 'Jelly Roll', 'Doja Cat', 'Jack Harlow', 'Dua Lipa', 'Tate McRae', 'Miley Cyrus', 'The Beatles', 'Mariah Carey', 'Peso Pluma', 'Rod Wave', 'Bad Bunny', 'Travis Scott', 'J. Cole', 'Michael Buble', 'The Weeknd', 'Noah Kahan', '21 Savage', 'Post Malone', 'Vince Guaraldi Trio', 'Nat King Cole', 'Paul Russell', 'Lainey Wilson', 'Brenda Lee', 'Billie Eilish', 'Tyla', 'Future', 'Bailey Zimmerman', 'Ariana Grande', 'Cher', 'Ed Sheeran', 'Andy Williams', 'Fleetwood Mac', 'Kendrick Lamar', 'Burl Ives', 'Harry Styles', 'Bing Crosby', 'Kanye West', 'Metro Boomin', 'Jason Aldean', 'Wham!', 'Dean Martin', 'Warren Zeiders', 'Frank Sinatra', 'Andre 3000', 'Chris Brown', 'Karol G', 'Bobby Helms', 'Gene Autry', 'Fuerza Regida', 'Jimmy Buffett', 'Tyler, The Creator', 'Evanescence', 'Kelly Clarkson', 'Bruno Mars', 'SEVENTEEN', 'Cody Johnson', 'Trans-Siberian Orchestra', 'Hozier', 'Gunna', 'Lana Del Rey', 'Mitski', 'Selena Gomez', 'Lil Baby', 'Teddy Swims', 'Metallica', 'Elvis Presley', 'Nirvana', 'Tyler Childers', 'Eagles', 'Darlene Love', 'Pearl Jam', 'Jordan Davis', 'Lil Wayne', 'Nate Smith', 'Pentatonix', 'Miguel', 'The Jacksons', 'TOMORROW X TOGETHER', 'Rihanna', 'HARDY', 'David Kushner', 'Jose Feliciano', 'Victoria Monet', 'The Ronettes', 'Eminem', 'Tory Lanez', 'Justin Bieber', 'The Rolling Stones'] ['1', '1', '3', '1', '5', '1', '1', '1', '1', '1', '1', '2', '4', '1', '1', '1', '17', '3', '2', '5', '5', '1', '1', '1', '1', '3', '1', '6', '3', '1', '11', '6', '33', '22', '17', '1', '37', '1', '9', '1', '2', '1', '7', '3', '1', '15', '1', '8', '1', '3', '1', '23', '21', '54', '13', '56', '1', '5', '28', '24', '31', '2', '1', '15', '2', '1', '1', '12', '19', '3', '1', '2', '8', '1', '1', '33', '2', '20', '20', '9', '10', '38', '3', '27', '1', '34', '1', '14', '55', '1', '1', '7', '51', '45', '48', '47', '1', '9', '1', '3'] ['1', '1', '3', '1', '5', '1', '1', '1', '1', '1', '1', '2', '4', '1', '1', '1', '17', '3', '2', '5', '5', '1', '1', '1', '1', '3', '1', '6', '3', '1', '11', '6', '33', '22', '17', '1', '37', '1', '9', '1', '2', '1', '7', '3', '1', '15', '1', '8', '1', '3', '1', '23', '21', '54', '13', '56', '1', '5', '28', '24', '31', '2', '1', '15', '2', '1', '1', '12', '19', '3', '1', '2', '8', '1', '1', '33', '2', '20', '20', '9', '10', '38', '3', '27', '1', '34', '1', '14', '55', '1', '1', '7', '51', '45', '48', '47', '1', '9', '1', '3'] ['487', '491', '29', '246', '30', '80', '132', '42', '422', '351', '221', '15', '71', '196', '136', '290', '59', '161', '301', '76', '37', '124', '295', '386', '361', '77', '437', '24', '169', '387', '55', '45', '12', '66', '42', '266', '6', '314', '78', '418', '13', '484', '50', '242', '412', '52', '230', '57', '244', '70', '443', '36', '37', '5', '57', '1', '415', '70', '31', '40', '33', '9', '127', '4', '113', '469', '37', '79', '58', '96', '147', '175', '12', '280', '289', '11', '418', '95', '181', '60', '219', '22', '14', '110', '50', '20', '93', '65', '16', '65', '290', '56', '16', '26', '7', '23', '455', '56', '457', '31']\n",
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "time.sleep(2)\n",
    "\n",
    "tab1=driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "tab1.click()\n",
    "time.sleep(25)\n",
    "\n",
    "tab2=driver.find_element(By.XPATH, '/html/body/div[3]/main/div[2]/div[1]/div[3]/div/div[2]/div[1]/a/span[1]')\n",
    "tab2.click()\n",
    "time.sleep(25)\n",
    "\n",
    "\n",
    "Data=[]\n",
    "PeakPos=[]\n",
    "ArtistName=[]\n",
    "Lastweekrank=[]\n",
    "Weekonboard=[]\n",
    "\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\")]')\n",
    "title_Child=titles.find_elements(By.XPATH, '//ul[contains(@class, \"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\")]//li')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Data.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Data.append(\"-\")\n",
    "\n",
    "for x in range(0,len(Data),12):\n",
    "    ArtistName.append(Data[x])\n",
    "for x in range(4,len(Data),12):\n",
    "    Lastweekrank.append(Data[x])\n",
    "for x in range(4,len(Data),12):\n",
    "    PeakPos.append(Data[x])\n",
    "for x in range(5,len(Data),12):\n",
    "    Weekonboard.append(Data[x])\n",
    "    \n",
    "print(ArtistName,Lastweekrank,PeakPos,Weekonboard)\n",
    "print(len(ArtistName),len(Lastweekrank),len(PeakPos),len(Weekonboard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c841b",
   "metadata": {},
   "source": [
    "Q6: Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7a1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Da Vinci Code,The', 'Harry Potter and the Deathly Hallows', \"Harry Potter and the Philosopher's Stone\", 'Harry Potter and the Order of the Phoenix', 'Fifty Shades of Grey', 'Harry Potter and the Goblet of Fire', 'Harry Potter and the Chamber of Secrets', 'Harry Potter and the Prisoner of Azkaban', 'Angels and Demons', \"Harry Potter and the Half-blood Prince:Children's Edition\", 'Fifty Shades Darker', 'Twilight', 'Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Fifty Shades Freed', 'Lost Symbol,The', 'New Moon', 'Deception Point', 'Eclipse', 'Lovely Bones,The', 'Curious Incident of the Dog in the Night-time,The', 'Digital Fortress', 'Short History of Nearly Everything,A', 'Girl Who Played with Fire,The:Millennium Trilogy', 'Breaking Dawn', 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar', 'Gruffalo,The', \"Jamie's 30-Minute Meals\", 'Kite Runner,The', 'One Day', 'Thousand Splendid Suns,A', \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\", \"Time Traveler's Wife,The\", 'Atonement', \"Bridget Jones's Diary:A Novel\", 'World According to Clarkson,The', \"Captain Corelli's Mandolin\", 'Sound of Laughter,The', 'Life of Pi', 'Billy Connolly', 'Child Called It,A', \"Gruffalo's Child,The\", \"Angela's Ashes:A Memoir of a Childhood\", 'Birdsong', 'Northern Lights:His Dark Materials S.', 'Labyrinth', 'Harry Potter and the Half-blood Prince', 'Help,The', 'Man and Boy', 'Memoirs of a Geisha', \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\", 'Island,The', 'PS, I Love You', 'You are What You Eat:The Plan That Will Change Your Life', 'Shadow of the Wind,The', 'Tales of Beedle the Bard,The', 'Broker,The', \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\", 'Subtle Knife,The:His Dark Materials S.', 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation', \"Delia's How to Cook:(Bk.1)\", 'Chocolat', 'Boy in the Striped Pyjamas,The', \"My Sister's Keeper\", 'Amber Spyglass,The:His Dark Materials S.', 'To Kill a Mockingbird', 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin', 'Dear Fatty', 'Short History of Tractors in Ukrainian,A', 'Hannibal', 'Lord of the Rings,The', 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio', 'Interpretation of Murder,The', 'Sharon Osbourne Extreme:My Autobiography', 'Alchemist,The:A Fable About Following Your Dream', \"At My Mother's Knee ...:and Other Low Joints\", 'Notes from a Small Island', 'Return of the Naked Chef,The', 'Bridget Jones: The Edge of Reason', \"Jamie's Italy\", 'I Can Make You Thin', 'Down Under', 'Summons,The', 'Small Island', 'Nigella Express', 'Brick Lane', \"Memory Keeper's Daughter,The\", 'Room on the Broom', 'About a Boy', 'My Booky Wook', 'God Delusion,The', '\"Beano\" Annual,The', 'White Teeth', 'House at Riverton,The', 'Book Thief,The', 'Nights of Rain and Stars', 'Ghost,The', 'Happy Days with the Naked Chef', 'Hunger Games,The:Hunger Games Trilogy', \"Lost Boy,The:A Foster Child's Search for the Love of a Family\", \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"] ['Brown, Dan', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'James, E. L.', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'Brown, Dan', 'Rowling, J.K.', 'James, E. L.', 'Meyer, Stephenie', 'Larsson, Stieg', 'James, E. L.', 'Brown, Dan', 'Meyer, Stephenie', 'Brown, Dan', 'Meyer, Stephenie', 'Sebold, Alice', 'Haddon, Mark', 'Brown, Dan', 'Bryson, Bill', 'Larsson, Stieg', 'Meyer, Stephenie', 'Carle, Eric', 'Donaldson, Julia', 'Oliver, Jamie', 'Hosseini, Khaled', 'Nicholls, David', 'Hosseini, Khaled', 'Larsson, Stieg', 'Niffenegger, Audrey', 'McEwan, Ian', 'Fielding, Helen', 'Clarkson, Jeremy', 'Bernieres, Louis de', 'Kay, Peter', 'Martel, Yann', 'Stephenson, Pamela', 'Pelzer, Dave', 'Donaldson, Julia', 'McCourt, Frank', 'Faulks, Sebastian', 'Pullman, Philip', 'Mosse, Kate', 'Rowling, J.K.', 'Stockett, Kathryn', 'Parsons, Tony', 'Golden, Arthur', 'McCall Smith, Alexander', 'Hislop, Victoria', 'Ahern, Cecelia', 'McKeith, Gillian', 'Zafon, Carlos Ruiz', 'Rowling, J.K.', 'Grisham, John', 'Atkins, Robert C.', 'Pullman, Philip', 'Truss, Lynne', 'Smith, Delia', 'Harris, Joanne', 'Boyne, John', 'Picoult, Jodi', 'Pullman, Philip', 'Lee, Harper', 'Gray, John', 'French, Dawn', 'Lewycka, Marina', 'Harris, Thomas', 'Tolkien, J. R. R.', 'Moore, Michael', 'Rubenfeld, Jed', 'Osbourne, Sharon', 'Coelho, Paulo', \"O'Grady, Paul\", 'Bryson, Bill', 'Oliver, Jamie', 'Fielding, Helen', 'Oliver, Jamie', 'McKenna, Paul', 'Bryson, Bill', 'Grisham, John', 'Levy, Andrea', 'Lawson, Nigella', 'Ali, Monica', 'Edwards, Kim', 'Donaldson, Julia', 'Hornby, Nick', 'Brand, Russell', 'Dawkins, Richard', '0', 'Smith, Zadie', 'Morton, Kate', 'Zusak, Markus', 'Binchy, Maeve', 'Harris, Robert', 'Oliver, Jamie', 'Collins, Suzanne', 'Pelzer, Dave', 'Oliver, Jamie'] ['5,094,805', '4,475,152', '4,200,654', '4,179,479', '3,758,936', '3,583,215', '3,484,047', '3,377,906', '3,193,946', '2,950,264', '2,479,784', '2,315,405', '2,233,570', '2,193,928', '2,183,031', '2,152,737', '2,062,145', '2,052,876', '2,005,598', '1,979,552', '1,928,900', '1,852,919', '1,814,784', '1,787,118', '1,783,535', '1,781,269', '1,743,266', '1,629,119', '1,616,068', '1,583,992', '1,555,135', '1,546,886', '1,539,428', '1,508,205', '1,489,403', '1,352,318', '1,310,207', '1,310,176', '1,231,957', '1,217,712', '1,208,711', '1,204,058', '1,184,967', '1,181,503', '1,181,093', '1,153,181', '1,132,336', '1,130,802', '1,126,337', '1,115,549', '1,108,328', '1,107,379', '1,104,403', '1,092,349', '1,090,847', '1,087,262', '1,054,196', '1,037,160', '1,023,688', '1,015,956', '1,009,873', '1,004,414', '1,003,780', '1,002,314', '998,213', '992,846', '986,753', '986,115', '970,509', '967,466', '963,353', '962,515', '959,496', '956,114', '945,640', '931,312', '925,425', '924,695', '906,968', '905,086', '890,847', '869,671', '869,659', '862,602', '856,540', '845,858', '842,535', '828,215', '820,563', '816,907', '816,585', '815,586', '814,370', '809,641', '808,900', '807,311', '794,201', '792,187', '791,507', '791,095'] ['Transworld', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Random House', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Transworld', 'Bloomsbury', 'Random House', 'Little, Brown Book', 'Quercus', 'Random House', 'Transworld', 'Little, Brown Book', 'Transworld', 'Little, Brown Book', 'Pan Macmillan', 'Random House', 'Transworld', 'Transworld', 'Quercus', 'Little, Brown Book', 'Penguin', 'Pan Macmillan', 'Penguin', 'Bloomsbury', 'Hodder & Stoughton', 'Bloomsbury', 'Quercus', 'Random House', 'Random House', 'Pan Macmillan', 'Penguin', 'Random House', 'Random House', 'Canongate', 'HarperCollins', 'Orion', 'Pan Macmillan', 'HarperCollins', 'Random House', 'Scholastic Ltd.', 'Orion', 'Bloomsbury', 'Penguin', 'HarperCollins', 'Random House', 'Little, Brown Book', 'Headline', 'HarperCollins', 'Penguin', 'Orion', 'Bloomsbury', 'Random House', 'Random House', 'Scholastic Ltd.', 'Profile Books Group', 'Random House', 'Transworld', 'Random House Childrens Books G', 'Hodder & Stoughton', 'Scholastic Ltd.', 'Random House', 'HarperCollins', 'Random House', 'Penguin', 'Random House', 'HarperCollins', 'Penguin', 'Headline', 'Little, Brown Book', 'HarperCollins', 'Transworld', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Transworld', 'Transworld', 'Random House', 'Headline', 'Random House', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Hodder & Stoughton', 'Transworld', 'D.C. Thomson', 'Penguin', 'Pan Macmillan', 'Transworld', 'Orion', 'Random House', 'Penguin', 'Scholastic Ltd.', 'Orion', 'Penguin'] ['Crime, Thriller & Adventure', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Romance & Sagas', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Crime, Thriller & Adventure', \"Children's Fiction\", 'Romance & Sagas', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Romance & Sagas', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Popular Science', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Picture Books', 'Picture Books', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Humour: Collections & General', 'General & Literary Fiction', 'Autobiography: General', 'General & Literary Fiction', 'Biography: The Arts', 'Autobiography: General', 'Picture Books', 'Autobiography: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Science Fiction & Fantasy', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'Fitness & Diet', 'General & Literary Fiction', \"Children's Fiction\", 'Crime, Thriller & Adventure', 'Fitness & Diet', 'Young Adult Fiction', 'Usage & Writing Guides', 'Food & Drink: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Popular Culture & Media: General Interest', 'Autobiography: The Arts', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Science Fiction & Fantasy', 'Current Affairs & Issues', 'Crime, Thriller & Adventure', 'Autobiography: The Arts', 'General & Literary Fiction', 'Autobiography: The Arts', 'Travel Writing', 'Food & Drink: General', 'General & Literary Fiction', 'National & Regional Cuisine', 'Fitness & Diet', 'Travel Writing', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'Picture Books', 'General & Literary Fiction', 'Autobiography: The Arts', 'Popular Science', \"Children's Annuals\", 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Food & Drink: General', 'Young Adult Fiction', 'Biography: General', 'Food & Drink: General']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "Book=[]\n",
    "AuthorName=[]\n",
    "Volume=[]\n",
    "Publ=[]\n",
    "Genre=[]\n",
    "\n",
    "#titles=driver.find_element(By.XPATH, '//table[contains(@class, \"in-article sortable\")]')\n",
    "title_Child=driver.find_elements(By.XPATH,'//table[contains(@class,\"in-article sortable\")]//tbody//tr//td[2]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Book.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Book.append(\"-\")\n",
    "        \n",
    "title_Child=driver.find_elements(By.XPATH,'//table[contains(@class,\"in-article sortable\")]//tbody//tr//td[3]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        AuthorName.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        AuthorName.append(\"-\")\n",
    "        \n",
    "title_Child=driver.find_elements(By.XPATH,'//table[contains(@class,\"in-article sortable\")]//tbody//tr//td[4]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Volume.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Volume.append(\"-\")\n",
    "        \n",
    "title_Child=driver.find_elements(By.XPATH,'//table[contains(@class,\"in-article sortable\")]//tbody//tr//td[5]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Publ.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Publ.append(\"-\")\n",
    "        \n",
    "title_Child=driver.find_elements(By.XPATH,'//table[contains(@class,\"in-article sortable\")]//tbody//tr//td[6]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append(\"-\")\n",
    "\n",
    "print(Book, AuthorName,Volume,Publ,Genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f62dd",
   "metadata": {},
   "source": [
    "Q7: Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a1ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'You', 'Dexter', 'Fear the Walking Dead', 'Family Guy', 'The Blacklist', 'Lost', 'Peaky Blinders', 'House', 'Quantico', 'Orphan Black', 'Homeland', 'Blindspot', \"DC's Legends of Tomorrow\", \"The Handmaid's Tale\", 'Chilling Adventures of Sabrina', 'The Good Doctor', 'Jane the Virgin', 'Glee', 'South Park', 'Brooklyn Nine-Nine', 'Under the Dome', 'The Umbrella Academy', 'True Detective', 'The OA', 'Desperate Housewives', 'Better Call Saul', 'Bates Motel', 'The Punisher', 'Atypical', 'Dynasty', 'This Is Us', 'The Good Place', 'Iron Fist', 'The Rain', 'Mindhunter', 'Revenge', 'Luke Cage', 'Scandal', 'The Defenders', 'Big Little Lies', 'Insatiable', 'The Mentalist', 'The Crown', 'Chernobyl', 'iZombie', 'Reign', 'A Series of Unfortunate Events', 'Criminal Minds', 'Scream: The TV Series', 'The Haunting of Hill House'] ['(2011–2019)', '(2016–2025)', '(2010–2022)', '(2017–2020)', '(2014–2020)', '(2013–2019)', '(2017–2023)', '(2005– )', '(2014–2023)', '(2012–2020)', '(2017–2021)', '(2007–2019)', '(2011– )', '(2010–2017)', '(2013–2020)', '(2010–2017)', '(2009–2017)', '(2011– )', '(2008– )', '(2016–2021)', '(2005–2020)', '(2005–2017)', '(2014–2020)', '(2011–2017)', '(1989– )', '(2011–2018)', '(I) (2015–2017)', '(2015–2018)', '(1994–2004)', '(2005–2014)', '(2011–2019)', '(2015–2019)', '(2013–2018)', '(2015–2021)', '(2007–2012)', '(2015–2018)', '(2014–2019)', '(2016–2022)', '(2015–2019)', '(2009–2020)', '(2013– )', '(2016–2019)', '(2017–2019)', '(2013–2018)', '(2017–2020)', '(2018–2024)', '(2019–2023)', '(2011–2021)', '(2011–2018)', '(2013–2020)', '(2018–2024)', '(2006–2013)', '(2015–2023)', '(1999– )', '(2013–2023)', '(2004–2010)', '(2013–2022)', '(2004–2012)', '(2015–2018)', '(2013–2017)', '(2011–2020)', '(2015–2020)', '(2016–2022)', '(2017– )', '(2018–2020)', '(2017– )', '(2014–2019)', '(2009–2015)', '(1997– )', '(2013–2021)', '(2013–2015)', '(2019–2024)', '(2014– )', '(2016–2019)', '(2004–2012)', '(2015–2022)', '(2013–2017)', '(2017–2019)', '(2017–2021)', '(2017–2022)', '(2016–2022)', '(2016–2020)', '(2017–2018)', '(2018–2020)', '(2017–2019)', '(2011–2015)', '(2016–2018)', '(2012–2018)', '(2017)', '(2017–2019)', '(2018–2019)', '(2008–2015)', '(2016–2023)', '(2019)', '(2015–2019)', '(2013–2017)', '(2017–2019)', '(2005– )', '(2015–2019)', '(2018)'] ['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Drama', 'Comedy, Romance', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Sci-Fi', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy, Romance', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Comedy, Crime, Drama', 'Drama, Horror, Mystery'] ['4,189 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '5,702 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '3,030 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '5,280 min', '4,576 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '3,804 min', '1,455 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '5,076 min', '44 min', '22 min', '43 min', '44 min', '2,109 min', '7,788 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '3,154 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '356 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min'] ['9.2', '8.7', '8.1', '7.5', '7.6', '8', '6.5', '7.6', '7.5', '7.5', '8.2', '8.2', '8.7', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.7', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.4', '8.5', '8.3', '6.2', '7.5', '8.2', '7.8', '8.5', '7.9', '8.5', '9.1', '6.5', '8', '8.7', '8.7', '7.2', '8.3', '8.5', '7.8', '7.5', '7.7', '8.7', '6.8', '8.2', '8', '8.3', '8.8', '8.7', '6.7', '8.3', '8.3', '7.3', '6.8', '8.4', '7.4', '8', '7.9', '6.8', '8.7', '8.4', '6.5', '7.9', '8.9', '7.8', '7.6', '9', '8.1', '8.5', '8.2', '7.3', '8.7', '8.2', '6.4', '6.3', '8.6', '7.8', '7.3', '7.7', '7.2', '8.4', '6.5', '8.2', '8.6', '9.3', '7.8', '7.5', '7.8', '8.1', '7', '8.6'] ['2,226,162', '1,293,229', '1,056,079', '310,082', '269,197', '315,956', '152,835', '332,493', '364,605', '442,580', '514,305', '848,230', '619,748', '975,062', '566,913', '175,723', '342,107', '337,512', '2,066,702', '346,826', '471,870', '567,471', '162,971', '160,081', '428,436', '233,928', '457,176', '464,746', '1,059,473', '716,110', '459,270', '409,373', '144,763', '128,314', '188,207', '160,677', '238,212', '524,209', '223,562', '467,288', '579,122', '68,776', '212,767', '523,618', '427,285', '88,526', '336,881', '270,035', '240,394', '223,799', '288,093', '751,582', '140,416', '358,004', '273,744', '582,486', '618,303', '495,140', '63,228', '115,524', '355,881', '77,876', '108,995', '252,465', '105,580', '108,886', '57,097', '153,912', '398,476', '347,259', '110,963', '267,257', '615,901', '112,182', '136,781', '617,519', '114,932', '257,371', '100,519', '24,417', '153,791', '181,766', '137,495', '40,521', '321,500', '123,712', '137,559', '78,577', '114,343', '218,128', '31,712', '196,160', '239,381', '832,252', '72,954', '53,263', '65,354', '213,132', '44,368', '277,921']\n",
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Runtime=[]\n",
    "Rating=[]\n",
    "Votes=[]\n",
    "\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"lister-list\")]')\n",
    "title_Child=titles.find_elements(By.XPATH, '//h3[contains(@class, \"lister-item-header\")]//a')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "title_Child=titles.find_elements(By.XPATH, '//span[contains(@class, \"lister-item-year text-muted unbold\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//div[contains(@class, \"lister-item-content\")]//p//span[5]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//div[contains(@class, \"lister-item-content\")]//p//span[3]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Runtime.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Runtime.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//div[contains(@class, \"ipl-rating-star small\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Rating.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Rating.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//div[contains(@class, \"lister-item-content\")]//p[4]//span[2]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Votes.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Votes.append(\"-\")\n",
    "        \n",
    "\n",
    "        \n",
    "print(Name,Year,Genre,Runtime,Rating,Votes)\n",
    "print(len(Name),len(Year),len(Genre),len(Runtime),len(Rating),len(Votes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3273f330",
   "metadata": {},
   "source": [
    "Q8: Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n",
    "ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e225d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris', 'Heart Disease', 'Adult', 'Wine', 'Breast Cancer Wisconsin (Diagnostic)', 'Diabetes', 'Dry Bean Dataset', 'Car Evaluation', 'Wine Quality', 'Rice (Cammeo and Osmancik)']\n",
      "['150 Instances', '303 Instances', '48.84K Instances', '178 Instances', '569 Instances', '1 Instances', '13.61K Instances', '1.73K Instances', '4.9K Instances', '3.81K Instances']\n",
      "['4 Features', '13 Features', '14 Features', '13 Features', '30 Features', '20 Features', '16 Features', '6 Features', '12 Features', '7 Features']\n",
      "['7/1/1988', '7/1/1988', '5/1/1996', '7/1/1991', '11/1/1995', 'N/A', '9/14/2020', '6/1/1997', '10/7/2009', '10/6/2019']\n",
      "['Real', 'Categorical, Integer, Real', 'Categorical, Integer', 'Integer, Real', 'Real', 'Categorical, Integer', 'Integer, Real', 'Categorical', 'Real', 'Real']\n",
      "['Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification, Regression', 'Classification']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\" https://archive.ics.uci.edu/\")\n",
    "time.sleep(5)\n",
    "\n",
    "tab0=driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "tab0.click()\n",
    "time.sleep(5)\n",
    "tab=driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]')\n",
    "tab.click()\n",
    "time.sleep(5)\n",
    "Datasetname=[]\n",
    "Instances=[]\n",
    "Year=[]\n",
    "AttributeCount=[]\n",
    "FeatureType=[]\n",
    "Task =[]\n",
    "Task1 =[]\n",
    "\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"flex flex-col gap-1\")]')\n",
    "title_Child=titles.find_elements(By.XPATH, '//h2[contains(@class, \"truncate text-primary\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Datasetname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Datasetname.append(\"-\")\n",
    "        \n",
    "title_Child1=titles.find_elements(By.XPATH, '//div[contains(@class, \"my-2 hidden gap-4 md:grid grid-cols-12\")]//div[3]')\n",
    "for i  in title_Child1:\n",
    "    try:\n",
    "        Instances.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append(\"-\")\n",
    "        \n",
    "title_Child5=titles.find_elements(By.XPATH, '//div[contains(@class, \"my-2 hidden gap-4 md:grid grid-cols-12\")]//div[1]')\n",
    "for i  in title_Child5:\n",
    "    try:\n",
    "        Task.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append(\"-\")\n",
    "for x in range(0,len(Task),5):\n",
    "    Task1.append(Task[x])\n",
    "    \n",
    "        \n",
    "title_Child2=titles.find_elements(By.XPATH, '//div[contains(@class, \"my-2 hidden gap-4 md:grid grid-cols-12\")]//div[4]')\n",
    "for i  in title_Child2:\n",
    "    try:\n",
    "        AttributeCount.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        AttributeCount.append(\"-\")\n",
    "        \n",
    "title_Child3=titles.find_elements(By.XPATH, '//div[contains(@class, \"grid grid-cols-8 overflow-x-auto\")]//table//tbody//tr//td[3]')\n",
    "for i  in title_Child3:\n",
    "    try:\n",
    "        Year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append(\"-\")\n",
    "        \n",
    "title_Child4=titles.find_elements(By.XPATH, '//div[contains(@class, \"grid grid-cols-8 overflow-x-auto\")]//table//tbody//tr//td[2]')\n",
    "for i  in title_Child4:\n",
    "    try:\n",
    "        FeatureType.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        FeatureType.append(\"-\")\n",
    "    \n",
    "    \n",
    "print(Datasetname)\n",
    "print(Instances)\n",
    "print(AttributeCount)\n",
    "print(Year)\n",
    "print(FeatureType)\n",
    "print(Task1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70d40a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book), len(AuthorName),len(Volume),len(Publ),len(Genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5954a9e",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8d4edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bgstaal / multipleWindow3dScene', 'run-llama / rags', 'teslamotors / roadster', 'trungdq88 / Awesome-Black-Friday-Cyber-Monday', 'fanmingming / live', 'keiko233 / clash-nyanpasu', 'linexjlin / GPTs', 'wesbos / hot-tips', 'lllyasviel / Fooocus', 'florinpop17 / app-ideas', 'StarRocks / starrocks', 'antirez / botlib', 'GrowingGit / GitHub-Chinese-Top-Charts', '1Panel-dev / 1Panel', 'LouisShark / chatgpt_system_prompt', 'Stability-AI / generative-models', 'AmruthPillai / Reactive-Resume', 'microsoft / AI-For-Beginners', 'fffaraz / awesome-cpp', 'mRs- / Black-Friday-Deals', 'spring-projects / spring-boot', 'windmill-labs / windmill', 'sergiomarotco / Network-segmentation-cheat-sheet', 'CatVodTVOfficial / TVBoxOSC', 'angular / angular'] ['A quick example of how one can \"synchronize\" a 3d scene across multiple windows using three.js and localStorage', 'Build ChatGPT over your data, all with natural language', '2008-2012 Roadster Development and Diagnostic Software files', 'Awesome deals on Black Friday: Apps, SaaS, Books, Courses, etc.', '✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不断完善的台标 支持IPv4/IPv6双栈访问 🔕', 'Clash Nyanpasu!', 'leaked prompts of GPTs', 'The code behind my hot tips', 'Focus on prompting and generating', 'A Collection of application ideas which can be used to improve your coding skills.', 'StarRocks, a Linux Foundation project, is a next-generation sub-second MPP OLAP database for full analytics scenarios, including multi-dimensional analytics, real-time analytics, and ad-hoc queries. InfoWorld’s 2023 BOSSIE Award for best open source software.', 'C Telegram bot framework', '🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需，高效学习。', '🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。', \"store all agent's system prompt\", 'Generative Models by Stability AI', 'A one-of-a-kind resume builder that keeps your privacy in mind. Completely secure, customizable, portable, open-source and free forever. Try it out today!', '12 Weeks, 24 Lessons, AI for All!', 'A curated list of awesome C++ (or C) frameworks, libraries, resources, and shiny things. Inspired by awesome-... stuff.', 'Black Friday Deals for macOS / iOS Software & Books', 'Spring Boot', 'Open-source developer platform to turn scripts into workflows and UIs. Open-source alternative to Airplane and Retool.', 'Best practices for segmentation of the corporate network of any company', '真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。', 'Deliver web apps with confidence 🚀'] ['1,076', '177', '', '197', '797', '', '2,077', '', '216', '', '469', '', '113', '1,393', '', '8,822', '', '1,344', '', '74', '9,860', '1,191', '', '196', '', '1,619', '', '1,662', '', '3,601', '', '7,472', '', '332', '', '39,807', '', '268', '', '241', '4,524', '', '24,777', ''] ['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java', 'TypeScript']\n",
      "25 25 44 19\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"Box\")]')\n",
    "title_Child=titles.find_elements(By.XPATH, '//h2[contains(@class, \"h3 lh-condensed\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Reptitle.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Reptitle.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//p[contains(@class, \"col-9 color-fg-muted my-1 pr-4\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        RepDesc.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        RepDesc.append(\"-\")\n",
    "        \n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//div[contains(@class, \"f6 color-fg-muted mt-2\")]//a[2]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        ContriCount.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        ContriCount.append(\"-\")\n",
    "        \n",
    "title_Child=titles.find_elements(By.XPATH, '//span[contains(@class, \"d-inline-block ml-0 mr-3\")]')\n",
    "for i  in title_Child:\n",
    "    try:\n",
    "        Languageused.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Languageused.append(\"-\")\n",
    "        \n",
    "        \n",
    "print(Reptitle,RepDesc,ContriCount,Languageused)\n",
    "print(len(Reptitle),len(RepDesc),len(ContriCount),len(Languageused))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a0a3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n",
      "Python\n",
      "JavaScript\n",
      "TypeScript\n",
      "HTML\n",
      "Python\n",
      "Java\n",
      "C\n",
      "Java\n",
      "Go\n",
      "Shell\n",
      "Python\n",
      "TypeScript\n",
      "Jupyter Notebook\n",
      "Swift\n",
      "Java\n",
      "JavaScript\n",
      "Java\n",
      "TypeScript\n",
      "['JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript', 'JavaScript']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"Box\")]//div[2]')\n",
    "title_Child=titles.find_elements(By.XPATH, '//article[contains(@class, \"Box-row\")]//div[2]//span//span[2]')\n",
    "for i  in title_Child:\n",
    "    print(i.text)\n",
    "    try:\n",
    "        tc=i.find_element(By.XPATH, '//span[contains(@class, \"d-inline-block ml-0 mr-3\")]')\n",
    "        Languageused.append(tc.text)\n",
    "    except NoSuchElementException:\n",
    "        Languageused.append(\"-\")\n",
    "        \n",
    "print(Languageused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bb8b92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JavaScript']\n",
      "['JavaScript', 'Python']\n",
      "['JavaScript', 'Python', 'JavaScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java', 'TypeScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java', 'TypeScript']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"Box\")]//div[2]')\n",
    "try:\n",
    "    title_Child=driver.find_elements(By.XPATH, '//article[contains(@class, \"Box-row\")]//div[2]//span//span[2]')\n",
    "    for i in title_Child:\n",
    "        Languageused.append(i.text)\n",
    "        print(Languageused)\n",
    "except NoSuchElementException:\n",
    "    Languageused.append(\"-\")\n",
    "    print(Languageused)\n",
    "print(Languageused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "75b5a53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_8\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_9\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_10\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_11\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_12\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_13\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_14\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_15\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_16\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_17\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"140c07ef3aa5579fd9a65a0a4df188d9\", element=\"7E4127969BBA338BE30BF392FB1967A4_element_26\")>]\n",
      "['JavaScript']\n",
      "['JavaScript', 'Python']\n",
      "['JavaScript', 'Python', 'JavaScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java', 'TypeScript']\n",
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java', 'TypeScript']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "titles=driver.find_element(By.XPATH, '//div[contains(@class, \"Box\")]//div[2]')\n",
    "\n",
    "title_Child=driver.find_elements(By.XPATH, '//article[contains(@class, \"Box-row\")]//div[2]//span//span[2]')\n",
    "print(title_Child)\n",
    "for i in title_Child:\n",
    "    Languageused.append(i.text)\n",
    "    print(Languageused)\n",
    "print(Languageused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parent class selector\n",
    "parent_class_selector = \".f6.color-fg-muted.mt-2\"\n",
    "\n",
    "# Find the parent element\n",
    "parent_element = driver.find_element_by_css_selector(parent_class_selector)\n",
    "\n",
    "# Define the class to search within the parent element\n",
    "class_to_find = \"d-inline-block.ml-0.mr-3\"\n",
    "\n",
    "# Find all elements with the specified class within the parent element\n",
    "elements_with_class = parent_element.find_elements_by_css_selector(f\".{class_to_find}\")\n",
    "\n",
    "# Check if elements with the specified class exist\n",
    "if elements_with_class:\n",
    "    print(\"Good\")\n",
    "else:\n",
    "    print(\"Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b77f67c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n",
      "Python\n",
      "-\n",
      "-\n",
      "JavaScript\n",
      "TypeScript\n",
      "-\n",
      "HTML\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "\n",
    "for x in range(1,10):\n",
    "#    titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]')\n",
    "#    print(titles.text)\n",
    "\n",
    "    try:\n",
    "        titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]//div//span//span[2]')\n",
    "#    ch_class=titles.find_element(By.XPATH, '//span[contains(@class, \"repo-language-color\")]')\n",
    "#        if titles:\n",
    "#        ch_class1=titles.find_element(By.XPATH, '//span[contains(@class, \"d-inline-block ml-0 mr-3\")]')\n",
    "        print(titles.text)\n",
    "    except NoSuchElementException:\n",
    "        print(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "\n",
    "# Start a WebDriver session and user input\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/trending\")\n",
    "time.sleep(2)\n",
    "\n",
    "Reptitle=[]\n",
    "RepDesc=[]\n",
    "ContriCount=[]\n",
    "Languageused=[]\n",
    "\n",
    "for x in range(1,10):\n",
    "#    titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]')\n",
    "#    print(titles.text)\n",
    "\n",
    "    try:\n",
    "        titles=driver.find_element(By.XPATH, f'//div[contains(@class, \"Box\")]//div[2]//article[{x}]//div//span//span[2]')\n",
    "#    ch_class=titles.find_element(By.XPATH, '//span[contains(@class, \"repo-language-color\")]')\n",
    "#        if titles:\n",
    "#        ch_class1=titles.find_element(By.XPATH, '//span[contains(@class, \"d-inline-block ml-0 mr-3\")]')\n",
    "        print(titles.text)\n",
    "    except NoSuchElementException:\n",
    "        print(\"-\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
